# Forecast an Echo State Network

Forecast an Echo State Network (ESN) from a trained model via recursive
forecasting. Forecast intervals are generated by simulating future
sample path based on a moving block bootstrap of the residuals and
estimating the quantiles from the simulations.

## Usage

``` r
forecast_esn(
  object,
  n_ahead = 18,
  levels = c(80, 95),
  n_sim = 100,
  n_seed = 42
)
```

## Arguments

- object:

  An object of class `esn`. The result of a call to
  [`train_esn()`](https://ahaeusser.github.io/echos/reference/train_esn.md).

- n_ahead:

  Integer value. The number of periods for forecasting (i.e. forecast
  horizon).

- levels:

  Numeric vector. The levels of the forecast intervals (in percent),
  e.g., `c(80, 95)`. Values must lie between 0 and 100.

- n_sim:

  Integer value. The number of simulated future paths used to compute
  forecast intervals via a moving block bootstrap of the (demeaned)
  in-sample residuals. If `NULL`, no intervals are computed.

- n_seed:

  Integer value. The seed for the random number generator (for
  reproducibility).

## Value

A `list` containing:

- `point`: Numeric vector containing the point forecasts.

- `interval`: Numeric matrix containing the forecast intervals.

- `sim`: Numeric matrix containing the simulated future sample path.

- `std`: Numeric vector with standard deviations.

- `levels`: Integer vector. The levels of the forecast intervals.

- `actual`: Numeric vector containing the actual values.

- `fitted`: Numeric vector containing the fitted values.

- `n_ahead`: Integer value. The number of periods for forecasting
  (forecast horizon).

- `model_spec`: Character value. The model specification as string.

## References

- Häußer, A. (2026). Echo State Networks for Time Series Forecasting:
  Hyperparameter Sweep and Benchmarking. arXiv preprint
  arXiv:2602.03912, 2026. <https://arxiv.org/abs/2602.03912>

- Jaeger, H. (2001). The “echo state” approach to analysing and training
  recurrent neural networks with an erratum note. Bonn, Germany: German
  National Research Center for Information Technology GMD Technical
  Report, 148(34):13.

- Jaeger, H. (2002). Tutorial on training recurrent neural networks,
  covering BPPT, RTRL, EKF and the "echo state network" approach.

- Lukosevicius, M. (2012). A practical guide to applying echo state
  networks. In Neural Networks: Tricks of the Trade: Second Edition,
  pages 659–686. Springer.

- Lukosevicius, M. and Jaeger, H. (2009). Reservoir computing approaches
  to recurrent neural network training. Computer Science Review,
  3(3):127–149.

## See also

Other base functions:
[`is.esn()`](https://ahaeusser.github.io/echos/reference/is.esn.md),
[`is.forecast_esn()`](https://ahaeusser.github.io/echos/reference/is.forecast_esn.md),
[`is.tune_esn()`](https://ahaeusser.github.io/echos/reference/is.tune_esn.md),
[`plot.esn()`](https://ahaeusser.github.io/echos/reference/plot.esn.md),
[`plot.forecast_esn()`](https://ahaeusser.github.io/echos/reference/plot.forecast_esn.md),
[`plot.tune_esn()`](https://ahaeusser.github.io/echos/reference/plot.tune_esn.md),
[`print.esn()`](https://ahaeusser.github.io/echos/reference/print.esn.md),
[`summary.esn()`](https://ahaeusser.github.io/echos/reference/summary.esn.md),
[`summary.tune_esn()`](https://ahaeusser.github.io/echos/reference/summary.tune_esn.md),
[`train_esn()`](https://ahaeusser.github.io/echos/reference/train_esn.md),
[`tune_esn()`](https://ahaeusser.github.io/echos/reference/tune_esn.md)

## Examples

``` r
xdata <- as.numeric(AirPassengers)
xmodel <- train_esn(y = xdata)
xfcst <- forecast_esn(xmodel, n_ahead = 12)
plot(xfcst)

```
