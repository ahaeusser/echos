% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ESN.R
\name{auto_esn}
\alias{auto_esn}
\title{Automatic train an Echo State Network}
\usage{
auto_esn(
  .data,
  specials,
  const = TRUE,
  lags = NULL,
  fourier = NULL,
  xreg = NULL,
  dy = 0,
  dx = 0,
  n_initial = 100,
  n_res = 200,
  n_seed = 42,
  alpha = 0.8,
  rho = 1,
  lambda = 1e-04,
  density = 0.1,
  type = 1,
  weights = NULL,
  penalty = NULL,
  scale_inputs = c(-1, 1),
  scale_runif = c(-0.5, 0.5),
  control_tuning = list(inf_crit = "aic", inputs_tune = FALSE, n_sample = 1000,
    pars_tune = TRUE, lower = c(1e-04, 0.01, 1e-08), upper = c(0.9999, 2.5, 0.001)),
  ...
)
}
\arguments{
\item{.data}{A \code{tsibble} containing the time series data.}

\item{specials}{Currently not is use.}

\item{const}{Logical value. If \code{TRUE}, a constant term (intercept) is used.}

\item{lags}{A \code{list} containing integer vectors with the lags associated with each input variable.}

\item{fourier}{A \code{list} containing the periods and the number of fourier terms as integer vector.}

\item{xreg}{A \code{tsibble} containing exogenous variables.}

\item{dy}{Integer vector. The nth-differences of the response variable.}

\item{dx}{Integer vector. The nth-differences of the exogenous variables.}

\item{n_initial}{Integer value. The number of observations of internal states for initial drop out (throw-off).}

\item{n_res}{Integer value. The number of internal states within the reservoir (hidden layer).}

\item{n_seed}{Integer value. The seed for the random number generator (for reproducibility).}

\item{alpha}{Numeric value. The leakage rate (smoothing parameter) applied to the reservoir.}

\item{rho}{Numeric value. The spectral radius for scaling the reservoir weight matrix.}

\item{lambda}{Numeric value. The regularization (shrinkage) parameter for ridge regression.}

\item{density}{Numeric value. The connectivity of the reservoir weight matrix (dense or sparse).}

\item{type}{Numeric value. The elastic net mixing parameter.}

\item{weights}{Numeric vector. Observation weights for weighted least squares estimation.}

\item{scale_inputs}{Numeric vector. The lower and upper bound for scaling the time series data.}

\item{scale_runif}{Numeric vector. The lower and upper bound of the uniform distribution.}

\item{control_tuning}{A \code{list} containing control values for the automatic tuning of model inputs and hyperparameters:
\itemize{
  \item{\code{inf_crit}: Character value. The information criterion used for tuning \code{inf_crit = c("aic", "bic", "hq")}.}
  \item{\code{inputs_tune}: Logical value. If \code{TRUE}, the model inputs are tuned, otherwise model inputs are used as defined.}
  \item{\code{n_sample}: Integer value. The number of samples for the random grid.}
  \item{\code{pars_tune}: Logical value. If \code{TRUE}, the hyperparameters are tuned, otherwise hyperparameters are used as defined.}
  \item{\code{lower}: Numeric vector. The lower bounds for \code{alpha}, \code{rho} and \code{lambda} used in the optimization.}
  \item{\code{upper}: Numeric vector. The upper bounds for \code{alpha}, \code{rho} and \code{lambda} used in the optimization.}
}}

\item{...}{Further arguments passed to \code{stats::optim()}}
}
\value{
An object of class \code{ESN}.
}
\description{
This function trains an Echo State Network (ESN)
  to a univariate time series.
}
